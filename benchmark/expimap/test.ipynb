{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scarches as sca\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to the dataset and model directory\n",
    "dataset = \"forebrain\"\n",
    "model = \"expimap\"\n",
    "model_path = f\"{dataset}/model\"\n",
    "\n",
    "# Load the saved EXPIMAP model\n",
    "adata_path = f\"{dataset}/{model}_{dataset}.h5ad\"\n",
    "adata = sc.read_h5ad(adata_path)\n",
    "\n",
    "# Assuming 'MuMs' and other necessary data are in `adata`\n",
    "data = adata.obsm[\"MuMs\"]\n",
    "adata_expimap = sc.AnnData(X=data)\n",
    "adata_expimap.uns[\"terms\"] = adata.uns[\"terms\"].copy()\n",
    "adata_expimap.obs = adata.obs.copy()\n",
    "mask = adata.varm[\"I\"]\n",
    "adata_expimap.varm[\"I\"] = np.concatenate([mask, mask], axis=0)\n",
    "\n",
    "# Add a dummy 'study' column to adata_expimap.obs as required by EXPIMAP\n",
    "adata_expimap.obs[\"study\"] = \"0\"\n",
    "\n",
    "# Load the saved EXPIMAP model\n",
    "intr_cvae = sca.models.EXPIMAP.load(model_path, adata=adata_expimap)\n",
    "\n",
    "# Now the model is loaded, and you can perform further analysis or use its methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get the number of observations (cells) in the dataset\n",
    "n_cells = adata_expimap.n_obs\n",
    "\n",
    "# Define the fraction used for training\n",
    "train_frac = 0.9\n",
    "\n",
    "# Set the seed if one was used during training to ensure reproducibility\n",
    "np.random.seed(2020)  # Seed used during training\n",
    "\n",
    "# Generate a shuffled list of indices\n",
    "all_indices = np.arange(n_cells)\n",
    "np.random.shuffle(all_indices)\n",
    "\n",
    "# Determine the number of training samples\n",
    "n_train = int(n_cells * train_frac)\n",
    "\n",
    "# Split the indices into training and testing sets\n",
    "train_indices = all_indices[:n_train]\n",
    "test_indices = all_indices[n_train:]\n",
    "\n",
    "print(f\"Training indices: {train_indices}\")\n",
    "print(f\"Test indices: {test_indices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Step 1: Extract the input data for the test indices\n",
    "input_data_test = adata_expimap.X[test_indices, :]  # Convert to dense if necessary\n",
    "\n",
    "# Step 2: Determine the device (CPU or GPU) from the model's parameters\n",
    "device = next(intr_cvae.model.parameters()).device  # Check the device of the model's parameters\n",
    "\n",
    "# Step 3: Use the model to reconstruct the data\n",
    "# Pass the input data through the model's decoder\n",
    "with torch.no_grad():  # Ensure the model doesn't compute gradients\n",
    "    input_tensor = torch.tensor(input_data_test).float().to(device)  # Ensure tensor is on the correct device\n",
    "    reconstructed_data_test = intr_cvae.model.decoder(input_tensor).cpu().numpy()  # Move the output back to CPU if necessary\n",
    "\n",
    "# Step 4: Compute MSE across genes for each cell\n",
    "mse_per_cell_test = np.mean((input_data_test - reconstructed_data_test) ** 2, axis=1)\n",
    "\n",
    "# Print or store the MSE for further analysis\n",
    "print(\"MSE per cell:\", mse_per_cell_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Input data shape: {input_data_test.shape}\")\n",
    "print(f\"Model input dimension: {intr_cvae.model.input_dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.varm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mask shape: {adata.varm['I'].shape}\")\n",
    "print(f\"Mask shape: {intr_cvae.model.mask.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model's attributes dictionary to see the expected conditions\n",
    "with open(f\"{model_path}/attr.pkl\", \"rb\") as f:\n",
    "    attr_dict = pickle.load(f)\n",
    "\n",
    "# Print the expected conditions\n",
    "print(\"Expected conditions:\", attr_dict['conditions_'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scarches as sca\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Load the saved EXPIMAP model\n",
    "dataset = \"forebrain\"\n",
    "model_path = f\"{dataset}/model\"\n",
    "adata_path = f\"{dataset}/expimap_{dataset}.h5ad\"\n",
    "adata = sc.read_h5ad(adata_path)\n",
    "\n",
    "data = adata.obsm[\"MuMs\"]\n",
    "adata_expimap = sc.AnnData(X=data)\n",
    "adata_expimap.uns[\"terms\"] = adata.uns[\"terms\"].copy()\n",
    "adata_expimap.obs = adata.obs.copy()\n",
    "mask = adata.varm[\"I\"]\n",
    "adata_expimap.varm[\"I\"] = np.concatenate([mask, mask], axis=0)\n",
    "\n",
    "# Initialize 'study' column in adata_expimap.obs to match expected condition\n",
    "adata_expimap.obs[\"study\"] = \"0\"  # Set to string '0' to match expected condition during training\n",
    "\n",
    "# Ensure 'study' column is of string type\n",
    "adata_expimap.obs[\"study\"] = adata_expimap.obs[\"study\"].astype(str)\n",
    "\n",
    "# Load the model ensuring the condition is already set in adata\n",
    "intr_cvae = sca.models.EXPIMAP.load(model_path, adata=adata_expimap)\n",
    "\n",
    "# Get the test indices from your earlier split\n",
    "n_cells = adata_expimap.n_obs\n",
    "train_frac = 0.9\n",
    "np.random.seed(2020)\n",
    "all_indices = np.arange(n_cells)\n",
    "np.random.shuffle(all_indices)\n",
    "n_train = int(n_cells * train_frac)\n",
    "train_indices = all_indices[:n_train]\n",
    "test_indices = all_indices[n_train:]\n",
    "\n",
    "# Extract test input data\n",
    "input_data_test = adata_expimap.X[test_indices, :]\n",
    "\n",
    "# Get the device\n",
    "device = next(intr_cvae.model.parameters()).device\n",
    "\n",
    "# Extract the condition labels for the test indices as a NumPy array\n",
    "condition_test = adata_expimap.obs[\"study\"].values[test_indices]\n",
    "\n",
    "# Create a mapping from condition labels to indices\n",
    "condition_to_label = {c: i for i, c in enumerate(intr_cvae.conditions_)}\n",
    "# Map the condition labels in condition_test to their corresponding indices\n",
    "condition_test_indices = np.array([condition_to_label[c] for c in condition_test])\n",
    "\n",
    "# Forward pass using the latent variables\n",
    "with torch.no_grad():\n",
    "    # Get the latent representation by passing input data and condition labels\n",
    "    z = intr_cvae.get_latent(x=input_data_test, c=condition_test)\n",
    "\n",
    "    # Convert z to a PyTorch tensor and move it to the correct device\n",
    "    z = torch.tensor(z).float().to(device)\n",
    "\n",
    "    # Prepare the batch tensor for the decoder\n",
    "    batch = torch.tensor(condition_test_indices).to(device)\n",
    "\n",
    "    # Pass the latent variables to the decoder to get the reconstructed data\n",
    "    reconstructed_data_test, _ = intr_cvae.model.decoder(z, batch=batch)\n",
    "    reconstructed_data_test = reconstructed_data_test.cpu().numpy()\n",
    "\n",
    "# Compute MSE across genes for each cell\n",
    "mse_per_cell_test = np.mean((input_data_test - reconstructed_data_test) ** 2, axis=1)\n",
    "print(\"MSE per cell:\", mse_per_cell_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intr_cvae.trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_per_cell_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Input data shape: {input_data_test.shape}\")  # Should be (N, 4898)\n",
    "print(f\"Mask shape: {adata_expimap.varm['I'].shape}\")  # Should align with features\n",
    "print(f\"Model input dimension: {intr_cvae.model.input_dim}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass with the condition\n",
    "with torch.no_grad():\n",
    "    input_tensor = torch.tensor(input_data_test).float().to(device)\n",
    "    output = intr_cvae.model(input_tensor, batch=condition_test)  # Pass the condition\n",
    "    \n",
    "    # Check what the output is by inspecting each element\n",
    "    print(f\"Output: {output}\")\n",
    "\n",
    "    # If we expect reconstructed data, let's inspect the individual components of the tuple\n",
    "    for i, part in enumerate(output):\n",
    "        print(f\"Part {i} - shape: {part.shape if isinstance(part, torch.Tensor) else part}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass using the latent variables\n",
    "with torch.no_grad():\n",
    "    # Assuming `get_latent()` encodes the input data\n",
    "    z = intr_cvae.get_latent(input_data_test)  # Get latent representation\n",
    "    \n",
    "    # Now pass the latent variables to the decoder to get the reconstructed data\n",
    "    reconstructed_data_test, _ = intr_cvae.model.decoder(z, batch=condition_test)\n",
    "    reconstructed_data_test = reconstructed_data_test.cpu().numpy()\n",
    "\n",
    "# Compute MSE across genes for each cell\n",
    "mse_per_cell_test = np.mean((input_data_test - reconstructed_data_test) ** 2, axis=1)\n",
    "print(\"MSE per cell:\", mse_per_cell_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepTrajectory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
