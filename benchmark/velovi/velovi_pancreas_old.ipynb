{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scvelo as scv\n",
    "import torch\n",
    "from velovi import preprocess_data, VELOVI\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from velovi_adapted_utils import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_mivelo, _ = load_files(\"pancreas\", 30)\n",
    "gnames = list(adata_mivelo.var_names)\n",
    "adata = scv.datasets.pancreas()\n",
    "adata = adata[:,gnames] #only keep gnames present in adata\n",
    "scv.pp.filter_and_normalize(adata, min_shared_counts=20)\n",
    "sc.pp.neighbors(adata)\n",
    "scv.pp.moments(adata, n_pcs=30, n_neighbors=30)\n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(adata, color=\"clusters\", show=False)\n",
    "plt.close()\n",
    "adata = preprocess_data(adata)\n",
    "VELOVI.setup_anndata(adata, spliced_layer=\"Ms\", unspliced_layer=\"Mu\")\n",
    "vae = VELOVI(adata)\n",
    "vae.train()\n",
    "fig, ax = plt.subplots()\n",
    "vae.history[\"elbo_train\"].iloc[20:].plot(ax=ax, label=\"train\")\n",
    "vae.history[\"elbo_validation\"].iloc[20:].plot(ax=ax, label=\"validation\")\n",
    "plt.legend()\n",
    "def add_velovi_outputs_to_adata(adata, vae):\n",
    "    latent_time = vae.get_latent_time(n_samples=25)\n",
    "    velocities = vae.get_velocity(n_samples=25, velo_statistic=\"mean\")\n",
    "    adata.layers[\"velocity_u\"] = vae.get_velocity(n_samples=25, velo_statistic=\"mean\", velo_mode=\"unspliced\")\n",
    "\n",
    "    t = latent_time\n",
    "    scaling = 20 / t.max(0)\n",
    "\n",
    "    adata.layers[\"velocity\"] = velocities / scaling\n",
    "    adata.layers[\"latent_time_velovi\"] = latent_time\n",
    "    adata.obsm[\"z\"] = vae.get_latent_representation(adata)\n",
    "\n",
    "    adata.var[\"fit_alpha\"] = vae.get_rates()[\"alpha\"] / scaling\n",
    "    adata.var[\"fit_beta\"] = vae.get_rates()[\"beta\"] / scaling\n",
    "    adata.var[\"fit_gamma\"] = vae.get_rates()[\"gamma\"] / scaling\n",
    "    adata.var[\"fit_t_\"] = (\n",
    "        torch.nn.functional.softplus(vae.module.switch_time_unconstr)\n",
    "        .detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    ) * scaling\n",
    "    scaling = np.array(scaling)\n",
    "    adata.layers[\"fit_t\"] = latent_time.values * scaling[np.newaxis, :]\n",
    "    adata.var['fit_scaling'] = 1.0\n",
    "\n",
    "add_velovi_outputs_to_adata(adata, vae)\n",
    "scv.tl.velocity_graph(adata)\n",
    "scv.pl.velocity_embedding_stream(adata, basis='umap')\n",
    "uncertainty_df, _ = vae.get_directional_uncertainty(n_samples=100)\n",
    "uncertainty_df.head()\n",
    "for c in uncertainty_df.columns:\n",
    "    adata.obs[c] = np.log10(uncertainty_df[c].values)\n",
    "sc.pl.umap(\n",
    "    adata, \n",
    "    color=\"directional_cosine_sim_variance\",\n",
    "    cmap=\"Greys\",\n",
    "    vmin=\"p1\",\n",
    "    vmax=\"p99\",\n",
    ")\n",
    "\n",
    "def compute_extrinisic_uncertainty(adata, vae, n_samples=25) -> pd.DataFrame:\n",
    "    from velovi._model import _compute_directional_statistics_tensor\n",
    "    from scvi.utils import track\n",
    "    from contextlib import redirect_stdout\n",
    "    import io\n",
    "\n",
    "    extrapolated_cells_list = []\n",
    "    for i in track(range(n_samples)):\n",
    "        with io.StringIO() as buf, redirect_stdout(buf):\n",
    "            vkey = \"velocities_velovi_{i}\".format(i=i)\n",
    "            v = vae.get_velocity(n_samples=1, velo_statistic=\"mean\")\n",
    "            adata.layers[vkey] = v\n",
    "            scv.tl.velocity_graph(adata, vkey=vkey, sqrt_transform=False, approx=True)\n",
    "            t_mat = scv.utils.get_transition_matrix(\n",
    "                adata, vkey=vkey, self_transitions=True, use_negative_cosines=True\n",
    "            )\n",
    "            extrapolated_cells = np.asarray(t_mat @ adata.layers[\"Ms\"])\n",
    "            extrapolated_cells_list.append(extrapolated_cells)\n",
    "    extrapolated_cells = np.stack(extrapolated_cells_list)\n",
    "    df, _ = _compute_directional_statistics_tensor(extrapolated_cells, n_jobs=-1, n_cells=adata.n_obs)\n",
    "    return df\n",
    "\n",
    "ext_uncertainty_df = compute_extrinisic_uncertainty(adata, vae)\n",
    "for c in ext_uncertainty_df.columns:\n",
    "    adata.obs[c + \"_extrinisic\"] = np.log10(ext_uncertainty_df[c].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata, \n",
    "    color=\"directional_cosine_sim_variance_extrinisic\",\n",
    "    vmin=\"p1\", \n",
    "    vmax=\"p99\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_df, _ = vae.get_permutation_scores(labels_key=\"clusters\")\n",
    "adata.var[\"permutation_score\"] = perm_df.max(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=adata.var, x=\"permutation_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_h5ad(\"adata.h5ad\")\n",
    "vae.save(\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepTrajectory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
